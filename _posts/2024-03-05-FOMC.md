# Aspect Based Sentiment Analysis_FOMC Minutes

## Introduction

After the 2008 financial crisis, the Federal Reserve adopted unconventional monetary policies on a large scale, such as forward guidance and quantitative easing (QE). To better understand the Federal Reserve's decision-making process under the new structure, I intend to study the relationship between **inflation** and **financial market**. Thus, this project aims to utilize a large language model to extract the official attitudes of the U.S. central bank towards domestic inflation and financial markets from [FOMC minutes](https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm). Subsequently, appropriate Markov Switching Models are applied to elucidate the evolving relationship between the two over time. The results indicate that from 2006 to 2023, the relationship between them is...

- **Input**

  Totaling 143 FOMC Minutes documents over 18 years, excerpt content as shown in Figure 1.

   
   ![](/images/FOMCminutes.png "Figure 1")


- **Middle Output**

   Employing the Latent Dirichlet Allocation (LDA) model for topic identification within the Minutes, three representative topics are identified: Economic Outlook, Financial Market, and Inflation. Then, utilizing the financial-specific large language model FinBERT to get the sentiment of each topic within the Minutes. This yields sentiment scores (ranged from -1 to 1)regarding the official attitudes towards each topic from 2006 to 2023. Figure 2 below illustrates the sentiment score plot over the studying period
  ![](/images/allYear.png "Figure 2")


- **Final Output**

  , further refined by a Markov Switching Model to discern the official attitudes towards Financial Market and Inflation.


   

## Analysis Step

**1. Using Web Crawler to get the FOMC Minutes files from the official website**

   - With the assistance of programming, by specifying the range of years for data retrieval, files can be obtained directly from official webpage.
   - Web scraping is particularly crucial for analyzing macroeconomic data, especially in this era of increasingly open data availability.

**2. Remove unnecessary texts from the Minutes that is not helpful for text information retrival**

   - In the initial pages of Minutes typically contain information about attendees' names and affiliated organizations, which are not particularly helpful for sentiment analysis. Therefore, I removed them.
   - 

**3. EDA**

   - numbers regarding the FOMC Minutes

       ![](/images/descriptive.png "Figure 3")
   - Paragraphs and words overtime

       ![](/images/year.png "Figure 4")
     
**4. Convert the data into suitable format**

  - Tokenize

       ![](/images/token.png "Figure 5")

**5. Topic modeling on the text files using LDA (Latent Dirichlet Allocation)**
   
   - Visualization

      ![](/images/catgory.png "Figure 6") 

**6. Financial-specific language model - FinBERT**

**7. Copula Modeling of Serially Correlated Multivariate Data with Hidden Structures**  


## Technical Challenge

### Data Preprocessing
- 

  Implementing 

### Model Building

#### FinBERT

![](/images/FINBERT.png "FinBERT structure") 

- **Feature extractor**: In segmentation models, feature extractor layers are used throughout the network, allowing it to process spatial information efficiently. These layers capture local patterns and structures in the input data.

- **Skip Connections**: To recover fine-grained details lost during downsampling, Unet uses skip connections. These connections combine feature maps from early layers with those from later layers, aiding in the reconstruction of high-resolution information.

- **Upsampling**: Segmentation models employ upsampling techniques to restore the spatial resolution of the feature maps. Transposed convolutions or bilinear interpolation can be used for this purpose.

#### Copula-based Markov Switching Model

![](/images/FINBERT.png "FinBERT structure") 

- **Feature extractor**: In segmentation models, feature extractor layers are used throughout the network, allowing it to process spatial information efficiently. These layers capture local patterns and structures in the input data.

- **Skip Connections**: To recover fine-grained details lost during downsampling, Unet uses skip connections. These connections combine feature maps from early layers with those from later layers, aiding in the reconstruction of high-resolution information.

- **Upsampling**: Segmentation models employ upsampling techniques to restore the spatial resolution of the feature maps. Transposed convolutions or bilinear interpolation can be used for this purpose.

#### Challenge encountered

- 

  After 

- 

  There 
  
- 

  I 

- 

  I 
  
### Evaluation


